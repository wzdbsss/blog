{"./":{"url":"./","title":"Java NullPointerException Debug","keywords":"","body":"Java NullPointerException Debug 前几天Analytics服务里job manager微服务接口报错，于是开始了捉虫之旅。感觉过程挺有意思，也许可以启发下大家，就写下来了。 登入k8s查看日志，发现是空指针异常。 c.s.m.a.c.u.RestTemplateInterceptor - In interceptor. Add authorization header for tenant altcdev 09:19:43.602 [cc5cf09e-2849-45ea-8871-cdd4f8c66774] [jmPollingTaskExecutor-3] [] ERROR c.s.m.a.s.a.CopyInputDataIntoS3Service - null java.lang.NullPointerException: null at com.siemens.mindsphere.analytics.service.activiti.CopyInputDataIntoS3Service.createFile(CopyInputDataIntoS3Service.java:209) at com.siemens.mindsphere.analytics.service.activiti.CopyInputDataIntoS3Service.moveFiles(CopyInputDataIntoS3Service.java:90) 这段代码业务逻辑是通过调用Data Exchange服务接口下载文件存储到阿里云oss bucket里面。经过初步排查发现DE并没有异常，我们的代码也看不出问题，并且开发环境并没有这个问题。而客户那边重现的几率非常大，只好又回到日志，对比了生产环境大量相同问题的日志，最后发现是抛异常的都是下载同一个文件的时候发生，那问题就出现在这个文件上了。 为了找到了问题源头，调用DE的文件properties接口查看文件描述，发现和其他文件的不同之处是这是一个0字节的空文件。是不是空文件会导致空指针异常？为了排除这个可能，开始从代码里寻找蛛丝马迹，直接定位到报错的类，定位到createFile方法用了restTemplate来发送http请求 CopyInputDataIntoS3Service.java 源码 ResponseEntity reponse = restTemplate.exchange(endpoint, HttpMethod.GET, entity, Resource.class); exchange方法将http response封装成ResponseEntity，接着调用reponse.getbody()就遇到了空指针异常。经过分析发现restTemplate使用ResoureHttpMessageConverter将http response封装为ByteArrayResource中的字节数组，便可通过调用Resource类的getInputStream()方法返回输入流，但如果http response为空，也就是空文件的情况，直接将body设置为null并返回。 至此问题原因明了，必须避免使用Resource.class作为返回类型，开始尝试自定义返回类型。 看了restTemplate中的方法，发现其中execute方法可以自定义responseExtractor，于是直接InputStream inputStream = copyFileRestTemplate.execute(endpoint, HttpMethod.GET, null, HttpInputMessage::getBody)返回输出流。然后调用阿里云oss sdk PutObjectRequest putObjectRequest = new PutObjectRequest(bucketName, keyPath, inputStream, new ObjectMetadata());将流传过去便成功了。 但是事情并没有这么简单。 改完以后SDK中 writeTo 方法 instream.read(buffer) 报错说流已关闭。com.aliyun.oss.common.comm.io.ChunkedInputStreamEntity.java 源码 // consume until EOF while ((l = instream.read(buffer)) != -1) { outstream.write(buffer, 0, l); } 这就很奇怪了，之前为什么没有出现这个报错？试了下非空文件现在也会出现 stream closed 错误！完全翻车。于是继续看源码，如上文所说，ResourceHttpMessageConverter将http response封装为ByteArrayResource中的字节数组，便可通过调用Resource类的getInputStream()方法返回输入流，所以重点是调用Resource类的子类ByteArrayResource中的getInputStream()方法返回输入流，这个流是ByteArrayResource内部的字节数组流，而http reponse中的流确实在方法执行完毕后就被关闭了。ResourceHttpMessageConverter.java 源码 if (Resource.class == clazz || ByteArrayResource.class.isAssignableFrom(clazz)) { byte[] body = StreamUtils.copyToByteArray(inputMessage.getBody()); 更坑爹的是其源码使用了this.pushbackInputStream = new PushbackInputStream(body)回退流来判断返回是否emptyMessage, 因此不会导致流被close, 真正close掉流的是RestTemplate类doExecute方法中的finally代码块。 finally { if (response != null) { response.close(); } } 于是只好重写doExecute方法，去掉finally代码块，这样便不会把stream close掉了。 class CopyFileRestTemplate extends RestTemplate { @Override protected T doExecute(URI url, HttpMethod method, RequestCallback requestCallback, ResponseExtractor responseExtractor) throws RestClientException { Assert.notNull(url, \"URI is required\"); Assert.notNull(method, \"HttpMethod is required\"); ClientHttpResponse response = null; try { ClientHttpRequest request = createRequest(url, method); if (requestCallback != null) { requestCallback.doWithRequest(request); } response = request.execute(); handleResponse(url, method, response); return (responseExtractor != null ? responseExtractor.extractData(response) : null); } catch (IOException ex) { String resource = url.toString(); String query = url.getRawQuery(); resource = (query != null ? resource.substring(0, resource.indexOf('?')) : resource); throw new ResourceAccessException(\"I/O error on \" + method.name() + \" request for \\\"\" + resource + \"\\\": \" + ex.getMessage(), ex); } } } 试了下修改以后空文件和非空文件都没有问题，这个bug终于完全的fix了。并且因为直接把流传给了oss的接口，使得我们的服务不再使用ByteArrayResource来通过字节数组缓存文件，因此可以减少部分内存占用。为了验证这个想法，登陆到k8s里的pod查看堆内存情况： 用jstat命令查看堆内存(相同参数调用) 修改前 eden space使用率大概 2.08G S0C S1C S0U S1U EC EU OC OU 419392.0 419392.0 64433.2 0.0 3355520.0 2084941.3 1048576.0 0.0 修改后 eden space使用率大概 1.75G S0C S1C S0U S1U EC EU OC OU 419392.0 419392.0 64426.8 0.0 3355520.0 1755979.1 1048576.0 0.0 可以看到年轻代堆内存占用确实比之前少了三百兆左右。 © wzdbsss all right reserved，powered by Gitbookmodified time: 2020-05-16 13:22:27 "},"Performance-Testing-Using-Apache-JMeter-master/PerformanceTest.html":{"url":"Performance-Testing-Using-Apache-JMeter-master/PerformanceTest.html","title":"Performance Testing Using Apache JMeter","keywords":"","body":"Performance Testing Using Apache JMeter Getting Start Download and install Apache JMeter from http://jmeter.apache.org/download_jmeter.cgi. Get a quick start at Performance testing tutorial (step by step), and you can get a full help at official website https://jmeter.apache.org/usermanual Example case for pattern matching Here we explore a more completely one. Download the example JMX Patternmatching.jmx and open it in your JMeter. In the first step we configure some variables and these variables can be refered by ${variable_key} in Jmeter. Then get web token from auth server before we start loading test, add a Thread Group and configure a HTTP Request as below. Once the token is delivered by response body, in next step JSON Extractor will be helpful, JSON Extractor is a tool inside Jmeter and it can parse the response body, we can use it getting the token. There is a farther explore for you about how to extract data from JSON: https://octoperf.com/blog/2017/03/09/how-to-extract-data-from-json-response-using-jmeter, once we get the specific data we can set it to Jmeter variables by ${__setProperty(token, ${token})} in BeanShell and simply use it by ${__property(token)} in another Thread Group. Remember configure token in the Header of loading testing Request. For many requests body is pretty large so we choose read it from file, there is another useful function for parametrization __FileToString. As its name suggests, this function reads the entire file every time it is called and stores it in a JMeter variable when data is inserted in the Variable Name parameter. In this case, we use ${__FileToString(${patterns_10_events_3000},,)} reading data from file patterns_10_events_3000, this input file contains 10 patterns, 3000 events for current request. Open terminal type jmeter -n -t Patternmatching.jmx -l Patternmatching.csv -e -o result to start test. Patternmatching.csv is log file samples which could be use for further analyzing, there is also a report dashboard after loading test. Distributed Testing Distributed testing allows for testing in a distributed environment. In a typical distributed environment, there are different machines each running a test engine instance and controlled by one primary machine or node. Distributed testing comes in handy when you have large number of users to simulate and test and a single machine is not good enough to handle such load. You can distribute the tests on different nodes The different nodes are controlled or managed by one single client node. Start slave nodes visit /bin directory to edit jmeter.properties file, disable JMeter running on a remote server over SSH by server.rmi.ssl.disable=true on each slave node start JMeter server with apache-jmeter-4.0/bin/jmeter-server -Djava.rmi.server.hostname=${slave_ip} Start master visit /bin directory to edit jmeter.properties file, disable JMeter running on a remote server over SSH as last step, adds IP slave machine as shown below: remote_hosts=${slave_ips} then start loading test withapache-jmeter-4.0/bin/jmeter -n -t /home/jmeter_master/jmeter/plan/Patternmatching.jmx -l /home/jmeter_master/jmeter/results/Patternmatching.csv -e -o /home/jmeter_master/jmeter/results/ -X -r Troubleshooting Always open jmeter(Unix)/jmeter.bat(Windows) to use Jmeter. Don't use GUI mode for load testing, only for Test creation and Test debugging. if you get problems such as Master won't shut down, you can start master with apache-jmeter-4.0/bin/jmeter -n -t /home/jmeter_master/jmeter/plan/Patternmatching.jmx -l /home/jmeter_master/jmeter/results/Patternmatching.csv -e -o /home/jmeter_master/jmeter/results/ -X -r -Djava.rmi.server.hostname=${host_ip} when distributing test reading request data from file, be careful the data path all the same on each nodes. © wzdbsss all right reserved，powered by Gitbookmodified time: 2020-05-16 13:22:27 "},"DockerfileGracefulTermination.html":{"url":"DockerfileGracefulTermination.html","title":"Dockerfile graceful termination","keywords":"","body":"Dockerfile best practice for graceful termination exec form v.s. shell form Refer to Official Docker ENTRYPOINT documentation, Docker ENTRYPOINT has two forms: ENTRYPOINT [\"executable\", \"param1\", \"param2\"] (exec form, preferred) ENTRYPOINT command param1 param2 (shell form) exec form shell form Command line arguments to docker run will be appended after all elements in an exec form ENTRYPOINT, and will override all elements specified using CMD. The shell form prevents any CMD or run command line arguments from being used, but has the disadvantage that your ENTRYPOINT will be started as a subcommand of /bin/sh -c, which does not pass signals. executable will be the container’s PID 1 - and will receive Unix signals - so your executable will receive a SIGTERM from docker stop . executable will not be the container’s PID 1 - and will not receive Unix signals - so your executable will not receive a SIGTERM from docker stop . does not invoke a command shell, which means that normal shell processing does not happen, e.g. no environment variable expansion like ${SW_AGENT_ENABLE} etc. environment variable expansion by /bin/sh process If the executable need graceful termination the preferred form is exec form, however exec form cannot pass the environment variables as parameter to executable. Shell form can pass the environment variables as parameter to executable via sh context, however it won't be the container's PID 1 process which won't receive a SIGTERM from docker stop for executable graceful termination. Solution to pass environment variable for graceful termination Refer to official doc Shell form ENTRYPOINT example, To ensure that docker stop will signal any long running ENTRYPOINT executable correctly, you need to remember to start it with exec as shell form ENTRYPOINT: FROM ubuntu ENTRYPOINT exec top -b To enable SW_AGENT_ENABLE environment variable for your Java Dockerfile ENTRYPOINT, please follow below example: Before: exex form without environment variable as java executable parameter & be the container's PID 1 for graceful termination. FROM openjdk:8-jdk-slim ADD ./build/libs/app.jar app.jar ENTRYPOINT [\"java\"] CMD [ \"-Djava.security.egd=file:/dev/./urandom\", \"-Dspring.profiles.active=secured,aliyun\", \"-jar\", \"/app.jar\" ] After: shell form with environment variable ${SW_AGENT_ENABLE} as java executable parameter & be the container's PID 1 for graceful termination. FROM openjdk:8-jdk-slim ADD ./build/libs/app.jar app.jar ENTRYPOINT exec java ${SW_AGENT_ENABLE} -Djava.security.egd=file:/dev/./urandom -Dspring.profiles.active=secured,aliyun -jar /app.jar © wzdbsss all right reserved，powered by Gitbookmodified time: 2020-05-16 13:22:27 "},"RemoteDebugK8sJavaApplication/RemoteDebugK8sJavaApplication.html":{"url":"RemoteDebugK8sJavaApplication/RemoteDebugK8sJavaApplication.html","title":"Remote Debug K8s Java Application","keywords":"","body":"Remote Debug K8s Java Application This page provide a way to using IDEA detach debug mode to debug java application that runs on Alibaba K8s cluster. Recommended Way: Install kubectl, get kubeconfig and write to file ~/.kube/config, then you can get cluster information by running $ kubectl cluster-info $ curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.12.0/bin/windows/amd64/kubectl.exe then add to system env. From IDEA, create remote debug attaching to localhost:, you will get JDK5~8 command line arguments -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=9090 Update Dockerfile to add arguments FROM openjdk:8-jdk-alpine ARG JAVA_ENABLE_DEBUG=false ENV JAVA_ENABLE_DEBUG ${JAVA_ENABLE_DEBUG} ADD ./dockerdemo-0.0.1-SNAPSHOT.jar demo.jar ENTRYPOINT if [ \"${JAVA_ENABLE_DEBUG}\" = \"true\" ]; then \\ java -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=9090 -Djava.security.egd=file:/dev/./urandom -jar /demo.jar; \\ else \\ java -Djava.security.egd=file:/dev/./urandom -jar /demo.jar; \\ fi EXPOSE 8080 Update K8s Pod yaml file and add JAVA_ENABLE_DEBUG as true ports: - containerPort: 5000 protocol: TCP - containerPort: 9090 name: jvm-debug protocol: TCP After started, getting pod by running $ kubectl get pod [-o wide] and forward local port to remote port by running $ kubectl port-forward : Run remote debug from IDEA, you will get Connected to the target VM, address: 'localhost:9090', transport: 'socket' upon success. Another Way: open project configuration add remote debug made the settings as marked by yellow Host & Port is the IP address of the service external endpoints in k8s. get the \"Command Line arguments for remote JVM\" in above screenshot and put into your Dockerfile as below: CMD [\"java\",\"-jar\",\"-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5000\",\"-Djava.security.egd=file:/dev/./urandom\",\"/devcockpitsvc-3.0.5.jar\"] build docker image and deploy. (might needs)restart service in k8s to restart service need to kill it start the remote debug task when your service starts to run, and you will see connected: © wzdbsss all right reserved，powered by Gitbookmodified time: 2020-05-16 13:22:27 "}}